# GPT-2 Fine-Tuning with KerasNLP

This project demonstrates how to fine-tune **GPT-2 base**
It includes training, saving, and loading a language model that can generate custom text.

---

## ðŸš€ Features
- Load the GPT-2 base model (`gpt2_base_en`) from KerasNLP presets.
- Fine-tune with a custom dataset.
- Compile with `AdamW` optimizer, weight decay, and categorical accuracy metric.
- Save and reload the trained model in the new **Keras v3 format**.
- Generate text with your fine-tuned model.

---
